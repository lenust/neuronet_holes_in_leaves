{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN/sP1ERQ+3GuhiiuxsU9rR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lenust/neuronet_holes_in_leaves/blob/main/To_train_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Connect your Google Drive and specify the folder where your data are located. This folder should contain the \"leaves_for_modelTRAIN\" folder, which contains intact leaves for model training"
      ],
      "metadata": {
        "id": "pUMh8qKCZ-WO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "google_drive_folder = \"/content/drive/MyDrive/neuronet for damaged area calculation\" # Replace with the path to your folder if necessary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJkgMuOlw0dk",
        "outputId": "16d91f39-cc19-4c37-9009-2baa38235af5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create functions to generate artificial damage on intact leaves. First method: Randomly generating groups of bites with each group having a random center point and radius, resulting in multiple concentric circles within that radius."
      ],
      "metadata": {
        "id": "nwhN4Pc0bFs7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image, ImageDraw\n",
        "import os\n",
        "import random\n",
        "\n",
        "# Define a function to to generate artificial damage (method1)\n",
        "def add_random_circles_to_image(image, min_num_groups, max_num_groups, min_radius, max_radius, min_circles, max_circles, min_circle_radius, max_circle_radius):\n",
        "    # Create a drawing object on the image\n",
        "    draw = ImageDraw.Draw(image)\n",
        "\n",
        "    # Generate a random number of groups of circles\n",
        "    num_groups = random.randint(min_num_groups, max_num_groups)\n",
        "    for i in range(num_groups):\n",
        "        # Choose a random point within the image\n",
        "        x = random.randint(0, image.width)\n",
        "        y = random.randint(0, image.height)\n",
        "\n",
        "        # Choose a random radius for this group of circles\n",
        "        radius = random.randint(min_radius, max_radius)\n",
        "\n",
        "        # Generate a random number of circles within this radius\n",
        "        num_circles = random.randint(min_circles, max_circles)\n",
        "        for j in range(num_circles):\n",
        "            # Generate random coordinates for each circle within the group\n",
        "            point_x = random.randint(x - radius, x + radius)\n",
        "            point_y = random.randint(y - radius, y + radius)\n",
        "\n",
        "            # Choose a random radius for each circle within the group\n",
        "            circle_radius = random.randint(min_circle_radius, int(radius * max_circle_radius))\n",
        "\n",
        "            # Draw the circle\n",
        "            draw.ellipse((point_x - circle_radius, point_y - circle_radius, point_x + circle_radius, point_y + circle_radius), fill=(255, 255, 255))\n",
        "\n",
        "    return image\n",
        "\n",
        "# Define a function to  to generate artificial damage (method1) to all images in a folder\n",
        "def add_random_circles_to_folder(input_folder, output_folder, min_num_groups, max_num_groups, min_radius, max_radius, min_circles, max_circles, min_circle_radius, max_circle_radius):\n",
        "    # Create the output folder if it doesn't exist\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    # Iterate through all files in the input folder\n",
        "    for filename in os.listdir(input_folder):\n",
        "        # Ignore files that are not image files\n",
        "        if not filename.endswith(('.jpg', '.jpeg', '.png', '.bmp', '.gif')):\n",
        "            continue\n",
        "\n",
        "        # Open the image\n",
        "        with Image.open(os.path.join(input_folder, filename)) as image:\n",
        "            # Add random circles to the image\n",
        "            image_with_circles = add_random_circles_to_image(image, min_num_groups, max_num_groups, min_radius, max_radius, min_circles, max_circles, min_circle_radius, max_circle_radius)\n",
        "\n",
        "            # Save the modified image to the output folder\n",
        "            new_filename = os.path.join(output_folder, filename)\n",
        "            image_with_circles.save(new_filename)"
      ],
      "metadata": {
        "id": "QOUrtCe8fPW0"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Second method: Randomly generating groups of bites, each with a random center point and a circle with a random radius. Subsequently, a random number of points were selected along the circumference of the initial circle, and additional circles with random radii were drawn at those points."
      ],
      "metadata": {
        "id": "dy2Cr2qYrogB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries and modules\n",
        "from PIL import Image, ImageDraw\n",
        "import os\n",
        "import random\n",
        "import math\n",
        "\n",
        "# Define a function to to generate artificial damage (method2)\n",
        "def add_random_circles_to_image2(image, min_num_groups, max_num_groups, min_radius, max_radius, min_circles, max_circles):\n",
        "    # Create a drawing object on the image\n",
        "    draw = ImageDraw.Draw(image)\n",
        "\n",
        "    # Generate a random number of groups of circles\n",
        "    num_groups = random.randint(min_num_groups, max_num_groups)\n",
        "    for i in range(num_groups):\n",
        "        # Choose a random point within the image\n",
        "        x = random.randint(0, image.width)\n",
        "        y = random.randint(0, image.height)\n",
        "\n",
        "        # Choose a random radius for this group of circles and draw the enclosing ellipse\n",
        "        radius = random.randint(min_radius, max_radius)\n",
        "        draw.ellipse((x - radius, y - radius, x + radius, y + radius), fill=(255, 255, 255))\n",
        "\n",
        "        # Generate a random number of circles within this radius\n",
        "        num_circles = random.randint(min_circles, max_circles)\n",
        "        for i in range(num_circles):\n",
        "            # Choose a random angle for the point\n",
        "            angle = random.uniform(0, 2 * math.pi)\n",
        "            # Calculate the coordinates of the point on the radius\n",
        "            point_x = x + int(radius * math.cos(angle))\n",
        "            point_y = y + int(radius * math.sin(angle))\n",
        "            # Choose a random radius for the circle and draw it\n",
        "            circle_radius = random.randint(min_radius, max_radius)\n",
        "            draw.ellipse((point_x - circle_radius, point_y - circle_radius, point_x + circle_radius, point_y + circle_radius), fill=(255, 255, 255))\n",
        "\n",
        "    return image\n",
        "\n",
        "# Define a function to generate artificial damage (method2) to all images in a folder\n",
        "def add_random_circles_to_folder2(input_folder, output_folder, min_num_groups, max_num_groups, min_radius, max_radius, min_circles, max_circles):\n",
        "    # Create the output folder if it doesn't exist\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    # Iterate through all files in the input folder\n",
        "    for filename in os.listdir(input_folder):\n",
        "        # Ignore files that are not image files\n",
        "        if not filename.endswith(('.jpg', '.jpeg', '.png', '.bmp', '.gif')):\n",
        "            continue\n",
        "\n",
        "        # Open the image\n",
        "        with Image.open(os.path.join(input_folder, filename)) as image:\n",
        "            # Add random circles to the image using the previous function\n",
        "            image_with_circles = add_random_circles_to_image2(image, min_num_groups, max_num_groups, min_radius, max_radius, min_circles, max_circles)\n",
        "\n",
        "            # Save the modified image to the output folder\n",
        "            new_filename = os.path.join(output_folder, filename)\n",
        "            image_with_circles.save(new_filename)\n",
        "\n"
      ],
      "metadata": {
        "id": "BLKYbSW0tqIC"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create the folder structure required for the model and call the functions to generate artificial damage on intact leaves with the specified parameters to create damages of high, medium and low degrees."
      ],
      "metadata": {
        "id": "23Kg2QLBr-Oo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# Create the 'leaves_for_modelTRAIN' folder and move images into 'source_leaves'\n",
        "leaves_for_modelTRAIN_folder = os.path.join(google_drive_folder, 'leaves_for_modelTRAIN')\n",
        "source_leaves_folder = os.path.join(leaves_for_modelTRAIN_folder, 'source_leaves')\n",
        "\n",
        "# Create the 'source_leaves' folder if it doesn't exist\n",
        "if not os.path.exists(source_leaves_folder):\n",
        "    os.makedirs(source_leaves_folder)\n",
        "\n",
        "# Move images from 'leaves_for_modelTRAIN' to 'source_leaves'\n",
        "for filename in os.listdir(leaves_for_modelTRAIN_folder):\n",
        "    # Check if the file is an image (e.g., .jpg, .jpeg, .png, etc.)\n",
        "    if filename.endswith(('.jpg', '.jpeg', '.png', '.bmp', '.gif')):\n",
        "        # Get the full path to the current image\n",
        "        image_path = os.path.join(leaves_for_modelTRAIN_folder, filename)\n",
        "\n",
        "        # Move the image to the 'source_leaves' folder\n",
        "        shutil.move(image_path, os.path.join(source_leaves_folder, filename))\n",
        "\n",
        "# Create 'Without' and 'With' folders\n",
        "without_folder = os.path.join(leaves_for_modelTRAIN_folder, 'Without')\n",
        "with_folder = os.path.join(leaves_for_modelTRAIN_folder, 'With')\n",
        "\n",
        "# Create 'Without' and 'With' folders if they don't exist\n",
        "if not os.path.exists(without_folder):\n",
        "    os.makedirs(without_folder)\n",
        "if not os.path.exists(with_folder):\n",
        "    os.makedirs(with_folder)\n",
        "\n",
        "# Create 7 copies of the 'source_leaves' folder inside 'Without'\n",
        "copy_folders = ['with_medium', 'with_small', 'with_big', 'with_medium2', 'with_small2', 'with_big2', 'without']\n",
        "for folder_name in copy_folders:\n",
        "    folder_path = os.path.join(without_folder, folder_name)\n",
        "    # Create a copy of the 'source_leaves' folder\n",
        "    shutil.copytree(source_leaves_folder, folder_path)\n",
        "\n",
        "# Create 1 copy of the 'source_leaves' folder inside 'With'\n",
        "with_without_folder = os.path.join(with_folder, 'without')\n",
        "# Create a copy of the 'source_leaves' folder\n",
        "shutil.copytree(source_leaves_folder, with_without_folder)\n",
        "\n",
        "# Get paths to folders for use in the 'add_random_circles_to_folder' function\n",
        "input_folder = source_leaves_folder\n",
        "with_medium_folder = os.path.join(with_folder, 'with_medium')\n",
        "with_small_folder = os.path.join(with_folder, 'with_small')\n",
        "with_big_folder = os.path.join(with_folder, 'with_big')\n",
        "with_medium_folder2 = os.path.join(with_folder, 'with_medium2')\n",
        "with_small_folder2 = os.path.join(with_folder, 'with_small2')\n",
        "with_big_folder2 = os.path.join(with_folder, 'with_big2')\n",
        "\n",
        "# Create the folders if they don't exist\n",
        "for folder in [with_medium_folder, with_small_folder, with_big_folder, with_medium_folder2, with_small_folder2, with_big_folder2]:\n",
        "    if not os.path.exists(folder):\n",
        "        os.makedirs(folder)\n",
        "\n",
        "# Call the 'add_random_circles_to_folder' and 'add_random_circles_to_folder2' functions with the specified parameters\n",
        "add_random_circles_to_folder(input_folder, with_medium_folder, min_num_groups=2, max_num_groups=3, min_radius=10, max_radius=60, min_circles=3, max_circles=6, min_circle_radius=5, max_circle_radius=2/3)\n",
        "add_random_circles_to_folder(input_folder, with_small_folder, min_num_groups=2, max_num_groups=3, min_radius=10, max_radius=20, min_circles=2, max_circles=5, min_circle_radius=2, max_circle_radius=3/4)\n",
        "add_random_circles_to_folder(input_folder, with_big_folder, min_num_groups=3, max_num_groups=6, min_radius=10, max_radius=70, min_circles=4, max_circles=8, min_circle_radius=5, max_circle_radius=2/3)\n",
        "\n",
        "add_random_circles_to_folder2(input_folder, with_small_folder2, min_num_groups=1, max_num_groups=3, min_radius=1, max_radius=10, min_circles=1, max_circles=10)\n",
        "add_random_circles_to_folder2(input_folder, with_medium_folder2, min_num_groups=2, max_num_groups=4, min_radius=3, max_radius=15, min_circles=3, max_circles=12)\n",
        "add_random_circles_to_folder2(input_folder, with_big_folder2, min_num_groups=5, max_num_groups=10, min_radius=5, max_radius=20, min_circles=5, max_circles=20)\n"
      ],
      "metadata": {
        "id": "3mBbYUdCuIBZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a folder with images for testing the model results"
      ],
      "metadata": {
        "id": "BQnXVFt0wYiH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the path to the 'test' folder\n",
        "test_folder = os.path.join(leaves_for_modelTRAIN_folder, 'test')\n",
        "\n",
        "# Create the 'test' folder if it doesn't exist\n",
        "if not os.path.exists(test_folder):\n",
        "    os.makedirs(test_folder)\n",
        "\n",
        "# Define the path to the 'test_with' folder inside 'test'\n",
        "test_with_folder = os.path.join(test_folder, 'test_with')\n",
        "\n",
        "# Create the 'test_with' folder inside 'test' if it doesn't exist\n",
        "if not os.path.exists(test_with_folder):\n",
        "    os.makedirs(test_with_folder)\n",
        "\n",
        "# List of folders from which to take two files each\n",
        "source_folders = [with_medium_folder, with_small_folder, with_big_folder, with_medium_folder2, with_small_folder2, with_big_folder2]\n",
        "\n",
        "# Loop through each of the specified folders\n",
        "for source_folder in source_folders:\n",
        "    # Get the list of files in the current folder\n",
        "    files = os.listdir(source_folder)\n",
        "\n",
        "    # Take the first two files (if they exist)\n",
        "    for i in range(2):\n",
        "        if i < len(files):\n",
        "            file_name = files[i]\n",
        "            # Full path to the file in the source folder\n",
        "            source_file_path = os.path.join(source_folder, file_name)\n",
        "            # Full path to the target folder ('test_with')\n",
        "            target_file_path = os.path.join(test_with_folder, file_name)\n",
        "            # Move the file to 'test_with'\n",
        "            shutil.move(source_file_path, target_file_path)\n",
        "\n",
        "# Define the path to the 'test_without' folder inside 'test'\n",
        "test_without_folder = os.path.join(test_folder, 'test_without')\n",
        "\n",
        "# Create the 'test_without' folder inside 'test' if it doesn't exist\n",
        "if not os.path.exists(test_without_folder):\n",
        "    os.makedirs(test_without_folder)\n",
        "\n",
        "# Get the list of files in the 'with_without_folder'\n",
        "without_files = os.listdir(with_without_folder)\n",
        "\n",
        "# Take the first two files (if they exist)\n",
        "for i in range(2):\n",
        "    if i < len(without_files):\n",
        "        file_name = without_files[i]\n",
        "        # Full path to the file in the source 'without' folder\n",
        "        source_file_path = os.path.join(with_without_folder, file_name)\n",
        "\n",
        "        # Create five copies of the file\n",
        "        for j in range(5):\n",
        "            # Full path to the target folder 'test_without'\n",
        "            target_file_name = f\"{file_name.split('.')[0]}_{j}.{file_name.split('.')[-1]}\"\n",
        "            target_file_path = os.path.join(test_without_folder, target_file_name)\n",
        "\n",
        "            # Copy the file to 'test_without'\n",
        "            shutil.copy(source_file_path, target_file_path)\n"
      ],
      "metadata": {
        "id": "ptrN4blh6KZd"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create objects of dataset class"
      ],
      "metadata": {
        "id": "gq6Xkz-f0KEW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "4dwZaasuGixJ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import cv2\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "\n",
        "# Define a function to load an image from a given path\n",
        "def load_image(path):\n",
        "    with open(path, 'rb') as f:\n",
        "        img = Image.open(f)\n",
        "        return transforms.Compose([transforms.ToTensor(), transforms.Resize((224, 224), antialias=True)])(img)\n",
        "\n",
        "# Define a function to binarize a tensor image using a threshold\n",
        "def binarize_image(tensor_image, threshold=190):\n",
        "    grayscale_image = tensor_image.mean(dim=0, keepdim=True)\n",
        "    grayscale_image = (grayscale_image * 255).numpy()\n",
        "\n",
        "    # Apply morphological closing operation to remove noise and improve object boundaries\n",
        "    kernel = np.ones((5, 5), np.uint8)\n",
        "    closed_image = cv2.morphologyEx(grayscale_image, cv2.MORPH_CLOSE, kernel)\n",
        "\n",
        "    binarized_image = (closed_image > threshold).astype(np.uint8)\n",
        "    return torch.from_numpy(binarized_image).float()\n",
        "\n",
        "# Define a custom dataset class that inherits from PyTorch's Dataset class\n",
        "class CustomDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, folder1, folder2):\n",
        "        self.folder1 = folder1\n",
        "        self.folder2 = folder2\n",
        "        self.filenames = self.get_filenames(folder1)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.filenames)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        filename = self.filenames[index]\n",
        "        img1_path = os.path.join(self.folder1, filename)\n",
        "        img2_path = os.path.join(self.folder2, filename)\n",
        "        img1 = load_image(img1_path)\n",
        "        img2 = load_image(img2_path)\n",
        "        img2_binarized = binarize_image(img2)\n",
        "        return (img1, img2_binarized)\n",
        "\n",
        "    def get_filenames(self, folder):\n",
        "        filenames = []\n",
        "        for root, dirs, files in os.walk(folder):\n",
        "            for file in files:\n",
        "                if os.path.isfile(os.path.join(root, file)):\n",
        "                    filenames.append(os.path.relpath(os.path.join(root, file), folder))\n",
        "        return filenames\n",
        "\n",
        "# Define paths to various folders\n",
        "leaves_for_modelTRAIN_folder = os.path.join(google_drive_folder, 'leaves_for_modelTRAIN')\n",
        "without_folder = os.path.join(leaves_for_modelTRAIN_folder, 'Without')\n",
        "with_folder = os.path.join(leaves_for_modelTRAIN_folder, 'With')\n",
        "test_folder = os.path.join(leaves_for_modelTRAIN_folder, 'test')\n",
        "test_without_folder = os.path.join(test_folder, 'test_without')\n",
        "test_with_folder = os.path.join(test_folder, 'test_with')\n",
        "\n",
        "# Create instances of the custom dataset for training and testing\n",
        "dataset = CustomDataset(with_folder, without_folder)\n",
        "dataset_test = CustomDataset(test_with_folder, test_without_folder)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the first ten samples from the training dataset, where each sample consists of an image and its corresponding mask and displays these images and masks using the show function."
      ],
      "metadata": {
        "id": "RFBo6vtt0jem"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ABdPtFjRCne9"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from torchvision.utils import make_grid\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Define a function to display a grid of images\n",
        "def show(images, cols=10):\n",
        "    cols = min(cols, len(images))\n",
        "    img_grid = make_grid(images[:cols], padding=10, nrow=cols)\n",
        "    plt.figure(figsize=(2 * cols, 2))\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(np.transpose(img_grid.numpy(), (1, 2, 0)))\n",
        "\n",
        "# Create data loaders for the training and test datasets\n",
        "train_loader = DataLoader(dataset, batch_size=8, shuffle=False)\n",
        "test_loader = DataLoader(dataset_test, batch_size=8, shuffle=False)\n",
        "\n",
        "# Initialize empty lists to store images and masks\n",
        "images = []\n",
        "masks = []\n",
        "\n",
        "# Iterate through the first ten samples in the training dataset\n",
        "for i in range(10):\n",
        "    # Get a pair of image and mask from the dataset\n",
        "    image, mask = dataset[i]\n",
        "    images.append(image)\n",
        "    masks.append(mask)\n",
        "\n",
        "# Display the first ten images and their masks\n",
        "print(\"First ten images of the train dataset and their masks (224x224 rescaled)\")\n",
        "show(images)\n",
        "show(masks)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install the segmentation-models-pytorch package\n",
        "Check if a GPU (CUDA) is available, and if so, set the device to CUDA; otherwise, set it to CPU."
      ],
      "metadata": {
        "id": "jdiMv8641xPm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hRwCHooNDRDM"
      },
      "outputs": [],
      "source": [
        "# Install the segmentation-models-pytorch package\n",
        "!pip install segmentation-models-pytorch\n",
        "\n",
        "# Clear the IPython output\n",
        "from IPython.display import clear_output\n",
        "clear_output()\n",
        "\n",
        "import torch\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # Check if GPU is available, set the device accordingly"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load fpom smp library segmentation model with the U-Net++ architecture.\n",
        "\n",
        "Define the loss function criterion as a combination of Dice Loss and Focal Loss. Define the optimizer."
      ],
      "metadata": {
        "id": "sk0w2pQU219b"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "WY5ENi6I02wa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07370aff-0353-49fb-ca42-9dd8c85ee9a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/efficientnet-b0-355c32eb.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet-b0-355c32eb.pth\n",
            "100%|██████████| 20.4M/20.4M [00:00<00:00, 182MB/s]\n"
          ]
        }
      ],
      "source": [
        "import segmentation_models_pytorch as smp\n",
        "import torch.optim as optim\n",
        "\n",
        "# Create a segmentation model using the U-Net++ architecture with an EfficientNet-B0 encoder\n",
        "# It's a binary segmentation model with a sigmoid activation function\n",
        "model = smp.UnetPlusPlus(encoder_name=\"efficientnet-b0\", classes=1, activation=\"sigmoid\")\n",
        "\n",
        "# Define the loss function as a combination of DiceLoss and FocalLoss\n",
        "# The loss function is weighted with 0.1 for DiceLoss and 0.9 for FocalLoss\n",
        "dice_loss = smp.losses.DiceLoss(mode='binary')\n",
        "focal_loss = smp.losses.FocalLoss('binary')\n",
        "criterion = lambda x, y: 0.1 * dice_loss(x, y) + 0.9 * focal_loss(x, y)\n",
        "\n",
        "# Move the model to the selected device (CPU or GPU)\n",
        "model.to(device)\n",
        "\n",
        "# Define the optimizer as AdamW with a learning rate of 0.0001 and weight decay of 1e-4\n",
        "optimizer = optim.AdamW(model.parameters(), lr=0.0001, weight_decay=1e-4)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define the train function that takes the model, loss criterion, optimizer, and optionally an epoch number and a list for storing predicted masks. It performs training and validation loops for a single epoch, calculates losses, and updates the model's weights. Additionally, it prints and logs training and validation loss for the current epoch."
      ],
      "metadata": {
        "id": "ar9BAHRw4KH9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "GRVOsC9qD5oz"
      },
      "outputs": [],
      "source": [
        "# Define a function for training the segmentation model\n",
        "def train(model, criterion, optimizer, epoch=None, masks_in_progress=[]):\n",
        "    ep_loss = 0  # Initialize the epoch loss to 0\n",
        "    model.train()  # Set the model to training mode\n",
        "    for img_batch, masks_batch in train_loader:  # Iterate through training data batches\n",
        "        optimizer.zero_grad()  # Zero out the gradients\n",
        "        output = model(img_batch.to(device))  # Forward pass: compute model predictions\n",
        "        loss = criterion(output, masks_batch.to(device))  # Calculate the loss\n",
        "        loss.backward()  # Backpropagation: compute gradients\n",
        "        optimizer.step()  # Update model weights using the optimizer\n",
        "        ep_loss += loss.item()  # Accumulate the epoch loss\n",
        "\n",
        "    val_loss = 0  # Initialize the validation loss to 0\n",
        "    for i, batch in enumerate(test_loader):  # Iterate through validation data batches\n",
        "        with torch.no_grad():  # Disable gradient computation for validation\n",
        "            img_batch, masks_batch = batch\n",
        "            output = model(img_batch.to(device))  # Forward pass for validation data\n",
        "            loss = criterion(output, masks_batch.to(device))  # Calculate validation loss\n",
        "            val_loss += loss.item()  # Accumulate the validation loss\n",
        "            if i == 0:\n",
        "                masks_in_progress.append(output[1].cpu())  # Store predicted masks for visualization\n",
        "\n",
        "    print(\n",
        "        \"Epoch {} Train loss {:.2f} Val loss {:.2f}\".format(\n",
        "            epoch, ep_loss / len(train_loader), val_loss / len(test_loader)\n",
        "        )\n",
        "    )  # Print and log training and validation loss for the current epoch\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the model for 120 epochs"
      ],
      "metadata": {
        "id": "hKv3XmCU4qAz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jIazmyHzD-2_"
      },
      "outputs": [],
      "source": [
        "%%time  # Measure the time taken for training\n",
        "masks_in_progress = []  # Initialize a list to store predicted masks during training\n",
        "\n",
        "# Iterate through a specified number of epochs (120 in this case)\n",
        "for epoch in range(120):\n",
        "    # Call the 'train' function to train the model for one epoch\n",
        "    train(model, criterion, optimizer, epoch, masks_in_progress)\n",
        "\n",
        "# Save the trained model's state dictionary to a file\n",
        "torch.save(model.state_dict(), os.path.join(google_drive_folder, \"trained_model\"))\n",
        "\n",
        "# Print a message indicating the completion of training and the location of the saved model\n",
        "print(f\"Training of the model is complete. The trained model is located in the folder {google_drive_folder}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Display the results of the neural network on images with artificially damaged leaves"
      ],
      "metadata": {
        "id": "igdQ20L-5KA3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B1jlagjcERgz"
      },
      "outputs": [],
      "source": [
        "from torchvision.utils import make_grid\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Define a function to display a grid of images\n",
        "def show(batch, cols=16, max_size=256):\n",
        "    cols = min(cols, len(batch))\n",
        "    # Create a grid of images with specified padding, normalization, and scaling\n",
        "    img_grid = make_grid(batch[:cols], padding=10, nrow=cols, normalize=True, scale_each=True, max_size=max_size)\n",
        "    plt.figure(figsize=(cols, cols))\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(np.transpose(img_grid.cpu().numpy(), (1, 2, 0)))\n",
        "\n",
        "# Define a function to display model predictions on the validation dataset\n",
        "def show_valset_pred(model, cols=16):\n",
        "    images, pred_masks = [], []\n",
        "    for batch in dataset_test:  # Iterate through the validation dataset\n",
        "        with torch.no_grad():\n",
        "            img, mask = batch\n",
        "            images.append(img.unsqueeze(0))  # Append the original image\n",
        "            output = model(img.unsqueeze(0).to(device))  # Forward pass for prediction\n",
        "            pred_masks.append(output.cpu())  # Append the predicted mask\n",
        "    # Display the original images, predicted masks, and the difference between them\n",
        "    show(torch.stack(images).squeeze()[:cols, ...])\n",
        "    show(torch.stack(pred_masks).squeeze(1)[:cols, ...])\n",
        "    show(torch.stack(pred_masks).squeeze(1)[:cols, ...] - torch.stack(images).squeeze()[:cols, ...])\n",
        "\n",
        "# Display the results of the neural network on images with artificially damaged leaves\n",
        "print(\"Neural network results on images with artificially damaged leaves\")\n",
        "show_valset_pred(model)\n"
      ]
    }
  ]
}